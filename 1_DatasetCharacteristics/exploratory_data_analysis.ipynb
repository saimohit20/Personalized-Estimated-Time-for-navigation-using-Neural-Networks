{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLH2jBYfHy2o"
      },
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "\n",
        "## Table of Contents\n",
        "1. [Libraries](#libraries)\n",
        "2. [Load data](#load-data)\n",
        "3. [Dataset overview](#dataset-overview)\n",
        "4. [Data format conversion](#data-format-conversion)\n",
        "5. [Dataset overview (single rider)](#possible-biases)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4yKkspkHy2p"
      },
      "source": [
        "## 1. Libraries\n",
        "Install and load necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install necessary files\n",
        "!pip install gpxpy\n",
        "!pip install tcxreader\n",
        "!pip install openpyxl"
      ],
      "metadata": {
        "id": "uFtVLW6cFbyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSmQCXP5Hy2q"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gpxpy\n",
        "import gpxpy.gpx\n",
        "import tcxreader\n",
        "import tcxreader.tcxreader\n",
        "import openpyxl\n",
        "import os\n",
        "import shutil\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load data\n",
        "Load whole dataset containing all tracks of 9 riders."
      ],
      "metadata": {
        "id": "VeXX-cHjOXVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "enc5tCy9E-RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Or upload local dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "VgUujNxzI1m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/opencampus_all_files/Sport1.zip -d /content"
      ],
      "metadata": {
        "id": "NoC_h4MU0WMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPhol6zGHy2r"
      },
      "source": [
        "## 3. Dataset Overview\n",
        "Basic exploration of the entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvmAsNqmHy2r"
      },
      "outputs": [],
      "source": [
        "# Load gpx.\n",
        "gpx_path = '/content/Sport/Rider1/f1.gpx'\n",
        "with open(gpx_path) as f:\n",
        "    gpx = gpxpy.parse(f)\n",
        "\n",
        "# Convert to a dataframe one point at a time.\n",
        "points = []\n",
        "for segment in gpx.tracks[0].segments:\n",
        "    for p in segment.points:\n",
        "        points.append({\n",
        "            'time': p.time,\n",
        "            'latitude': p.latitude,\n",
        "            'longitude': p.longitude,\n",
        "            'elevation': p.elevation,\n",
        "        })\n",
        "df = pd.DataFrame.from_records(points)\n",
        "\n",
        "# Number of samples\n",
        "num_samples = df.shape[0]\n",
        "\n",
        "# Number of features\n",
        "num_features = df.shape[1]\n",
        "\n",
        "# Display these dataset characteristics\n",
        "print(f\"Number of samples: {num_samples}\")\n",
        "print(f\"Number of features: {num_features}\")\n",
        "\n",
        "# Display the first few rows of the dataframe to show the structure\n",
        "print(\"Example data:\")\n",
        "print(df.head())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the main folder containing Rider folders\n",
        "main_path = '/content/Sport'\n",
        "\n",
        "# Iterate through each Rider folder and count the number of .gpx files\n",
        "for rider_folder in sorted(os.listdir(main_path)):\n",
        "    folder_path = os.path.join(main_path, rider_folder)\n",
        "    if os.path.isdir(folder_path):\n",
        "        gpx_files = [f for f in os.listdir(folder_path) if f.endswith('.gpx')]\n",
        "        tcx_files = [f for f in os.listdir(folder_path) if f.endswith('.tcx')]\n",
        "        print(f\"Folder '{rider_folder}' contains {len(gpx_files)} .gpx files and {len(tcx_files)} .tcx files.\")\n"
      ],
      "metadata": {
        "id": "t813gaFl5gHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data format conversion\n",
        "Convert GPX and TCX to XLS format. In order to correctly analyse all the data its format should be firstly unified."
      ],
      "metadata": {
        "id": "2bOhLPztOTOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_gpx_to_excel(gpx_file_path, output_file_path):\n",
        "  # Initialize a DataFrame to store data\n",
        "  all_data = []\n",
        "\n",
        "  # Parse the GPX file\n",
        "  with open(gpx_file_path, 'r') as gpx_file:\n",
        "      gpx = gpxpy.parse(gpx_file)\n",
        "\n",
        "  # Extract data (latitude, longitude, elevation, time, etc.)\n",
        "  for track in gpx.tracks:\n",
        "      for segment in track.segments:\n",
        "          for point in segment.points:\n",
        "              # Convert timezone-aware datetime to timezone-naive\n",
        "              naive_time = point.time.replace(tzinfo=None) if point.time else None\n",
        "\n",
        "              all_data.append({\n",
        "                  'Latitude': point.latitude,\n",
        "                  'Longitude': point.longitude,\n",
        "                  'Elevation': point.elevation,\n",
        "                  'Time': naive_time\n",
        "              })\n",
        "\n",
        "  # Convert the data into a DataFrame\n",
        "  df = pd.DataFrame(all_data)\n",
        "\n",
        "  # Write the DataFrame to an Excel file\n",
        "  df.to_excel(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "kMaGWKktMxgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TCX to XLSX\n",
        "def convert_tcx_to_excel(tcx_file_path, output_file_path):\n",
        "    \"\"\"\n",
        "    Converts a TCX file to an Excel file with trackpoint data.\n",
        "\n",
        "    Parameters:\n",
        "    - tcx_file_path: str, path to the input TCX file\n",
        "    - output_file_path: str, path to save the output Excel file\n",
        "    \"\"\"\n",
        "    # Initialize the TCX reader\n",
        "    tcx_reader = TCXReader()\n",
        "\n",
        "    # Read the TCX file\n",
        "    data: TCXExercise = tcx_reader.read(tcx_file_path)\n",
        "\n",
        "    # List to store the trackpoint data\n",
        "    trackpoint_data = []\n",
        "\n",
        "    # Loop through all trackpoints and extract relevant information\n",
        "    for trackpoint in data.trackpoints:\n",
        "        trackpoint_data.append({\n",
        "            'Time': trackpoint.time,\n",
        "            'Latitude': trackpoint.latitude,\n",
        "            'Longitude': trackpoint.longitude,\n",
        "            'Elevation': trackpoint.elevation,\n",
        "            'Distance': trackpoint.distance,\n",
        "            'Heartrate': trackpoint.hr_value,\n",
        "            'Cadence': trackpoint.cadence,\n",
        "            'Speed': trackpoint.tpx_ext['Speed']\n",
        "        })\n",
        "\n",
        "    # Convert the list of dictionaries to a pandas DataFrame\n",
        "    df = pd.DataFrame(trackpoint_data)\n",
        "\n",
        "    # Save the DataFrame to an Excel file\n",
        "    df.to_excel(output_file_path, index=False, engine='openpyxl')\n"
      ],
      "metadata": {
        "id": "RgEU9KOlQm6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directories\n",
        "sport_dir = \"/content/Sport\"\n",
        "sport_xlsx_dir = \"/content/Sport_xlsx\"\n",
        "\n",
        "# Create Sport_xlsx directory if it doesn't exist\n",
        "if not os.path.exists(sport_xlsx_dir):\n",
        "    os.makedirs(sport_xlsx_dir)\n",
        "\n",
        "# Function to convert files in a folder\n",
        "def convert_files_in_folder(rider_folder):\n",
        "    rider_xlsx_folder = os.path.join(sport_xlsx_dir, rider_folder)\n",
        "\n",
        "    # Create the rider folder in Sport_xlsx directory if it doesn't exist\n",
        "    if not os.path.exists(rider_xlsx_folder):\n",
        "        os.makedirs(rider_xlsx_folder)\n",
        "\n",
        "    rider_folder_path = os.path.join(sport_dir, rider_folder)\n",
        "\n",
        "    # Process .gpx files\n",
        "    gpx_files = [f for f in os.listdir(rider_folder_path) if f.endswith('.gpx')]\n",
        "    for gpx_file in gpx_files:\n",
        "        convert_gpx_to_excel(os.path.join(rider_folder_path, gpx_file),\n",
        "                           os.path.join(rider_xlsx_folder, gpx_file.replace('.gpx', '.xlsx')))\n",
        "\n",
        "    # Process .tcx files\n",
        "    tcx_files = [f for f in os.listdir(rider_folder_path) if f.endswith('.tcx')]\n",
        "    for tcx_file in tcx_files:\n",
        "        convert_tcx_to_excel(os.path.join(rider_folder_path, tcx_file),\n",
        "                           os.path.join(rider_xlsx_folder, tcx_file.replace('.tcx', '.xlsx')))\n"
      ],
      "metadata": {
        "id": "0IOfK69AV-J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Riders = ['Rider1', 'Rider2', 'Rider3', 'Rider4', 'Rider5', 'Rider6', 'Rider7', 'Rider8', 'Rider9']\n",
        "for rider in Riders:\n",
        "  convert_files_in_folder(rider)"
      ],
      "metadata": {
        "id": "WTCMFC3jfFD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/Sport_xlsx/Rider1.zip /content/Sport_xlsx/Rider1"
      ],
      "metadata": {
        "id": "maWIkJuUH48E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Dataset overview (Single rider)\n",
        "Load and exploration of a single rider files after succesful conversion to xlsx format."
      ],
      "metadata": {
        "id": "l-6YHPY8nYE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/opencampus_all_files/Rider1.zip -d /content"
      ],
      "metadata": {
        "id": "CYHrWKGInlJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/content/Sport_xlsx/Rider1/'\n",
        "\n",
        "# Initialize lists and dictionaries to store results\n",
        "row_counts = []\n",
        "missing_values = 0\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for file in os.listdir(directory):\n",
        "    if file.endswith(\".xlsx\"):\n",
        "        file_path = os.path.join(directory, file)\n",
        "\n",
        "        # Read the Excel file\n",
        "        df = pd.read_excel(file_path)\n",
        "\n",
        "        # Count rows and add to list\n",
        "        row_counts.append(df.shape[0])\n",
        "\n",
        "        # Count missing values\n",
        "        missing_values += df.isnull().sum()"
      ],
      "metadata": {
        "id": "UH64q_vDoXJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the missing values summary\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "5ZGhlbG2xtN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the histogram of row counts\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(row_counts, bins=30, color='blue', alpha=0.7)\n",
        "plt.title(\"Histogram of Row Counts\")\n",
        "plt.xlabel(\"Number of Rows\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jZ9lPedwxr5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the boxplot of row counts\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.boxplot(row_counts)\n",
        "plt.title(\"Boxplot of Row Counts\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1MQHr0lQxvRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(row_counts))"
      ],
      "metadata": {
        "id": "ZVhmkg78x0b7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(row_counts))"
      ],
      "metadata": {
        "id": "ntK1LH8abkyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = '/content/content/Sport_xlsx/Rider1/'\n",
        "\n",
        "# Initialize lists to store results\n",
        "total_seconds = []\n",
        "file_names = []\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for file in os.listdir(directory):\n",
        "    if file.endswith(\".xlsx\"):\n",
        "        file_path = os.path.join(directory, file)\n",
        "\n",
        "        # Read the Excel file\n",
        "        df = pd.read_excel(file_path)\n",
        "\n",
        "        # Convert timestamps to absolute value\n",
        "        df['Time'] = pd.to_datetime(df['Time'])\n",
        "        df['Time'] = (df['Time'] - df['Time'][0]).dt.total_seconds()\n",
        "\n",
        "        # Count length of each file\n",
        "        total_seconds.append(df['Time'].iloc[-1])\n",
        "        file_names.append(file)  # Store the filename\n",
        "\n",
        "# Create a DataFrame for analysis\n",
        "results_df = pd.DataFrame({'File': file_names, 'TrackLength': total_seconds})"
      ],
      "metadata": {
        "id": "zLZuf7O4ys0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the histogram of file lengths\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(total_seconds, bins=30, color='blue', alpha=0.7)\n",
        "plt.title(\"Histogram of Track Lenght\")\n",
        "plt.xlabel(\"Number of Rows\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E5De0FIRz4rM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the boxplot of file lenghts\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.boxplot(total_seconds)\n",
        "plt.title(\"Boxplot of Track Lenght\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VHq7tXKBz9B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sorted(total_seconds))"
      ],
      "metadata": {
        "id": "J9glzOLHzgAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the file with the outlier\n",
        "outlier_value = results_df['TrackLength'].max()  # Assuming the outlier is the maximum value\n",
        "outlier_file = results_df[results_df['TrackLength'] == outlier_value]\n",
        "print(\"Outlier file(s):\")\n",
        "print(outlier_file)"
      ],
      "metadata": {
        "id": "e9CV4Dg6JaAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the folder path\n",
        "folder_path = '/content/Sport/Rider1/'\n",
        "\n",
        "# Collect all GPX files in the folder\n",
        "gpx_files = [file for file in os.listdir(folder_path) if file.endswith('.gpx')]\n",
        "\n",
        "# Prepare a list for storing all tracks\n",
        "all_tracks = []\n",
        "\n",
        "# Parse each GPX file and extract track data\n",
        "for gpx_file in gpx_files:\n",
        "    file_path = os.path.join(folder_path, gpx_file)\n",
        "    with open(file_path, 'r') as f:\n",
        "        gpx = gpxpy.parse(f)\n",
        "        for track in gpx.tracks:\n",
        "            for segment in track.segments:\n",
        "                latitudes = [point.latitude for point in segment.points]\n",
        "                longitudes = [point.longitude for point in segment.points]\n",
        "                all_tracks.append((latitudes, longitudes))\n",
        "\n",
        "# Plot the tracks\n",
        "plt.figure(figsize=(10, 8))\n",
        "for latitudes, longitudes in all_tracks:\n",
        "    plt.plot(longitudes, latitudes, color='black', linewidth=0.5)\n",
        "\n",
        "plt.title(\"Tracks from GPX Files\")\n",
        "plt.xlabel(\"Longitude\")\n",
        "plt.ylabel(\"Latitude\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "guK2EM8rGoWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_tracks_with_low_coords(folder_path, max_longitude=10, max_latitude=40):\n",
        "    \"\"\"\n",
        "    Identifies GPX files with tracks extending below the specified longitude or latitude.\n",
        "\n",
        "    Parameters:\n",
        "        folder_path (str): Path to the folder containing GPX files.\n",
        "        max_longitude (float): Longitude threshold to check (files with points below this are flagged).\n",
        "        max_latitude (float): Latitude threshold to check (files with points below this are flagged).\n",
        "\n",
        "    Returns:\n",
        "        List of filenames matching the criteria.\n",
        "    \"\"\"\n",
        "    flagged_files = []\n",
        "\n",
        "    # Loop through all GPX files in the folder\n",
        "    for gpx_file in os.listdir(folder_path):\n",
        "        if gpx_file.endswith('.gpx'):\n",
        "            file_path = os.path.join(folder_path, gpx_file)\n",
        "            with open(file_path, 'r') as f:\n",
        "                try:\n",
        "                    gpx = gpxpy.parse(f)\n",
        "\n",
        "                    # Check all track points\n",
        "                    for track in gpx.tracks:\n",
        "                        for segment in track.segments:\n",
        "                            for point in segment.points:\n",
        "                                if point.longitude < max_longitude or point.latitude < max_latitude:\n",
        "                                    flagged_files.append(gpx_file)\n",
        "                                    raise StopIteration  # Exit nested loops early\n",
        "                except StopIteration:\n",
        "                    continue  # Move to the next file\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {gpx_file}: {e}\")\n",
        "\n",
        "    return flagged_files\n",
        "\n",
        "# Example usage\n",
        "folder_path = '/content/Sport/Rider1/'\n",
        "files_with_low_coords = find_tracks_with_low_coords(folder_path)\n",
        "\n",
        "print(\"Files with tracks extending below 10 Longitude or 40 Latitude:\")\n",
        "for file in files_with_low_coords:\n",
        "    print(file)"
      ],
      "metadata": {
        "id": "7EkNXiF9Njcw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
