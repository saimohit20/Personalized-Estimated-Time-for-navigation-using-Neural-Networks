{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLH2jBYfHy2o"
      },
      "source": [
        "# Preprocessing pipeline\n",
        "\n",
        "## Table of Contents\n",
        "1. [Libraries](#libraries)\n",
        "2. [Change format](#change-format)\n",
        "4. [Preprocessing](#preprocessing)\n",
        "5. [Save output](#save-output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4yKkspkHy2p"
      },
      "source": [
        "## 1. Libraries\n",
        "Install and load necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install necessary files\n",
        "!pip install gpxpy\n",
        "!pip install tcxreader\n",
        "!pip install openpyxl"
      ],
      "metadata": {
        "id": "uFtVLW6cFbyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSmQCXP5Hy2q"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gpxpy\n",
        "import gpxpy.gpx\n",
        "import tcxreader\n",
        "import tcxreader.tcxreader\n",
        "import openpyxl\n",
        "import os\n",
        "import shutil\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Change format\n",
        "Convert GPX and TCX to XLS format. In order to correctly analyse all the data its format should be firstly unified."
      ],
      "metadata": {
        "id": "JsNNdxKG2aID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "outputId": "4d238d85-19aa-4572-c705-9fb5bd7e33b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR3vkICl2oZE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or upload local dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "7YyPlAZD2oZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/opencampus_all_files/Sport1.zip -d /content"
      ],
      "metadata": {
        "id": "vustPiKP2oZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_gpx_to_excel(gpx_file_path, output_file_path):\n",
        "  # Initialize a DataFrame to store data\n",
        "  all_data = []\n",
        "\n",
        "  # Parse the GPX file\n",
        "  with open(gpx_file_path, 'r') as gpx_file:\n",
        "      gpx = gpxpy.parse(gpx_file)\n",
        "\n",
        "  # Extract data (latitude, longitude, elevation, time, etc.)\n",
        "  for track in gpx.tracks:\n",
        "      for segment in track.segments:\n",
        "          for point in segment.points:\n",
        "              # Convert timezone-aware datetime to timezone-naive\n",
        "              naive_time = point.time.replace(tzinfo=None) if point.time else None\n",
        "\n",
        "              all_data.append({\n",
        "                  'Latitude': point.latitude,\n",
        "                  'Longitude': point.longitude,\n",
        "                  'Elevation': point.elevation,\n",
        "                  'Time': naive_time\n",
        "              })\n",
        "\n",
        "  # Convert the data into a DataFrame\n",
        "  df = pd.DataFrame(all_data)\n",
        "\n",
        "  # Write the DataFrame to an Excel file\n",
        "  df.to_excel(output_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "0bEVwFmA2aIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TCX to XLSX\n",
        "def convert_tcx_to_excel(tcx_file_path, output_file_path):\n",
        "    \"\"\"\n",
        "    Converts a TCX file to an Excel file with trackpoint data.\n",
        "\n",
        "    Parameters:\n",
        "    - tcx_file_path: str, path to the input TCX file\n",
        "    - output_file_path: str, path to save the output Excel file\n",
        "    \"\"\"\n",
        "    # Initialize the TCX reader\n",
        "    tcx_reader = TCXReader()\n",
        "\n",
        "    # Read the TCX file\n",
        "    data: TCXExercise = tcx_reader.read(tcx_file_path)\n",
        "\n",
        "    # List to store the trackpoint data\n",
        "    trackpoint_data = []\n",
        "\n",
        "    # Loop through all trackpoints and extract relevant information\n",
        "    for trackpoint in data.trackpoints:\n",
        "        trackpoint_data.append({\n",
        "            'Time': trackpoint.time,\n",
        "            'Latitude': trackpoint.latitude,\n",
        "            'Longitude': trackpoint.longitude,\n",
        "            'Elevation': trackpoint.elevation,\n",
        "            'Distance': trackpoint.distance,\n",
        "            'Heartrate': trackpoint.hr_value,\n",
        "            'Cadence': trackpoint.cadence,\n",
        "            'Speed': trackpoint.tpx_ext['Speed']\n",
        "        })\n",
        "\n",
        "    # Convert the list of dictionaries to a pandas DataFrame\n",
        "    df = pd.DataFrame(trackpoint_data)\n",
        "\n",
        "    # Save the DataFrame to an Excel file\n",
        "    df.to_excel(output_file_path, index=False, engine='openpyxl')\n"
      ],
      "metadata": {
        "id": "dNAxcGSP2aIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directories\n",
        "sport_dir = \"/content/Sport\"\n",
        "sport_xlsx_dir = \"/content/Sport_xlsx\"\n",
        "\n",
        "# Create Sport_xlsx directory if it doesn't exist\n",
        "if not os.path.exists(sport_xlsx_dir):\n",
        "    os.makedirs(sport_xlsx_dir)\n",
        "\n",
        "# Function to convert files in a folder\n",
        "def convert_files_in_folder(rider_folder):\n",
        "    rider_xlsx_folder = os.path.join(sport_xlsx_dir, rider_folder)\n",
        "\n",
        "    # Create the rider folder in Sport_xlsx directory if it doesn't exist\n",
        "    if not os.path.exists(rider_xlsx_folder):\n",
        "        os.makedirs(rider_xlsx_folder)\n",
        "\n",
        "    rider_folder_path = os.path.join(sport_dir, rider_folder)\n",
        "\n",
        "    # Process .gpx files\n",
        "    gpx_files = [f for f in os.listdir(rider_folder_path) if f.endswith('.gpx')]\n",
        "    for gpx_file in gpx_files:\n",
        "        convert_gpx_to_excel(os.path.join(rider_folder_path, gpx_file),\n",
        "                           os.path.join(rider_xlsx_folder, gpx_file.replace('.gpx', '.xlsx')))\n",
        "\n",
        "    # Process .tcx files\n",
        "    tcx_files = [f for f in os.listdir(rider_folder_path) if f.endswith('.tcx')]\n",
        "    for tcx_file in tcx_files:\n",
        "        convert_tcx_to_excel(os.path.join(rider_folder_path, tcx_file),\n",
        "                           os.path.join(rider_xlsx_folder, tcx_file.replace('.tcx', '.xlsx')))\n"
      ],
      "metadata": {
        "id": "KAcSQdV92aIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Riders = ['Rider1', 'Rider2', 'Rider3', 'Rider4', 'Rider5', 'Rider6', 'Rider7', 'Rider8', 'Rider9']\n",
        "for rider in Riders:\n",
        "  convert_files_in_folder(rider)"
      ],
      "metadata": {
        "id": "FTbj-y5B2aIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Preprocessing\n",
        "Necessary steps before training model on the data:\n",
        "- Delete files recorded outside Europe\n",
        "- Repair corrupted file (f97)\n",
        "- Convert timestamp to seconds\n",
        "\n",
        "Optional feature engineering:\n",
        "- Calculate distance since beginning\n"
      ],
      "metadata": {
        "id": "H4yH-hEM2B00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from the drive\n",
        "!zip -r /content/Sport_xlsx/Rider1.zip /content/Sport_xlsx/Rider1"
      ],
      "metadata": {
        "id": "o8giTvJE2aIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing pipeline\n",
        "import pandas as pd\n",
        "import os\n",
        "from geopy.distance import geodesic\n",
        "from pyproj import Transformer\n",
        "\n",
        "def preprocess_rider_data(input_dir, output_dir):\n",
        "    for filename in os.listdir(input_dir):\n",
        "        if filename.endswith(\".xlsx\"):\n",
        "            filepath = os.path.join(input_dir, filename)\n",
        "            try:\n",
        "                df = pd.read_excel(filepath)\n",
        "\n",
        "                # Step 1: If file is f97.xlsx, delete the first 11 rows\n",
        "                if filename == \"f97.xlsx\":\n",
        "                    df = df.iloc[11:].reset_index(drop=True)\n",
        "\n",
        "                # Step 2: Delete the file if max_longitude < 10 or max_latitude < 40\n",
        "                if df['Longitude'].max() < 10 or df['Latitude'].max() < 40:\n",
        "                    print(f\"File {filename} deleted due to coordinates.\")\n",
        "                    os.remove(filepath)\n",
        "                    continue  # Skip the rest of the loop for this file\n",
        "\n",
        "                # Step 3: Convert timestamp to seconds\n",
        "                df['Time'] = pd.to_datetime(df['Time'])\n",
        "                df['Time'] = (df['Time'] - df['Time'].iloc[0]).dt.total_seconds()\n",
        "\n",
        "                # Step 4: Calculate distance since the beginning\n",
        "                distances = []\n",
        "                cumulative_distance = 0\n",
        "                for i in range(len(df)):\n",
        "                    if i > 0:\n",
        "                        previous_coords = (df['Latitude'].iloc[i-1], df['Longitude'].iloc[i-1])\n",
        "                        current_coords = (df['Latitude'].iloc[i], df['Longitude'].iloc[i])\n",
        "                        distance = geodesic(previous_coords, current_coords).meters\n",
        "                        cumulative_distance += distance\n",
        "                    else:\n",
        "                        distance = 0\n",
        "                    distances.append(cumulative_distance)\n",
        "                df['Distance'] = distances\n",
        "\n",
        "                # Step 5: Save the preprocessed file\n",
        "                output_filepath = os.path.join(output_dir, filename)\n",
        "                df.to_excel(output_filepath, index=False)\n",
        "                print(f\"Processed and saved: {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {e}\")\n",
        "\n",
        "\n",
        "# Example usage (replace with your actual paths):\n",
        "input_directory = '/content/content/Sport_xlsx/Rider1/'\n",
        "output_directory = '/content/content/Sport_xlsx/Rider1_preprocessed/'\n",
        "\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "preprocess_rider_data(input_directory, output_directory)"
      ],
      "metadata": {
        "id": "6ZPNrUrP2B01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Save output\n",
        "Initial preprocessing output exported and saved to drive for the further utilization."
      ],
      "metadata": {
        "id": "EQwNy-Cq3sis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/content/Sport_xlsx/Rider1_preprocessed.zip /content/content/Sport_xlsx/Rider1_preprocessed"
      ],
      "metadata": {
        "id": "at_eKcKC2B01"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}