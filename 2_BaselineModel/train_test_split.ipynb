{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNZAJ2Iy7UfB"
      },
      "source": [
        "# Rider 1 - Split into train and test\n",
        "\n",
        "## Table of Contents\n",
        "1. [Libraries](#libraries)\n",
        "2. [Load dataset](#load-dataset)\n",
        "3. [Feature engineering](#feature-engineering)\n",
        "4. [Data cleaning](#data-cleaning)\n",
        "5. [Export train and test](#export-train-and-test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZJLTK337UfI"
      },
      "source": [
        "## 1. Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "id": "ibI_fHbUQjF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oto5BB4t0pf2"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "import random\n",
        "import os\n",
        "import openpyxl\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load dataset\n",
        "Load preprocessed dataset and print basic details."
      ],
      "metadata": {
        "id": "c8G5_jmE0tPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Directory preparation"
      ],
      "metadata": {
        "id": "HtNm_r8A3Btz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "3MWauQ3N06KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Replace 'path/to/your/zipped_folder.zip' with the actual path to your zipped folder in Google Drive.\n",
        "zip_path = '/content/drive/MyDrive/opencampus_all_files/Rider1_preprocessed.zip'\n",
        "\n",
        "# Extract the contents of the zip file to a specified directory.\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/Rider1_preprocessed')\n",
        "\n",
        "print(f\"Successfully unzipped {zip_path} to /content/Rider1_preprocessed\")\n"
      ],
      "metadata": {
        "id": "2QrIoYu01hR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_dir = '/content/Rider1_preprocessed/content/content/Sport_xlsx/Rider1_preprocessed'\n",
        "destination_dir = '/content/Rider1_preprocessed'\n",
        "\n",
        "# Iterate through all files in the source directory\n",
        "for filename in os.listdir(source_dir):\n",
        "    source_path = os.path.join(source_dir, filename)\n",
        "    destination_path = os.path.join(destination_dir, filename)\n",
        "\n",
        "    # Check if it's a file (not a subdirectory)\n",
        "    if os.path.isfile(source_path):\n",
        "        # Move the file\n",
        "        shutil.move(source_path, destination_path)"
      ],
      "metadata": {
        "id": "P-k6juQO13gC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory to clean\n",
        "directory_to_clean = '/content/Rider1_preprocessed'\n",
        "\n",
        "# Check if the directory exists\n",
        "if os.path.exists(directory_to_clean):\n",
        "    for filename in os.listdir(directory_to_clean):\n",
        "        filepath = os.path.join(directory_to_clean, filename)\n",
        "        try:\n",
        "            if os.path.isdir(filepath):\n",
        "                shutil.rmtree(filepath)  # Remove folders recursively\n",
        "                print(f\"Removed directory: {filepath}\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error removing {filepath}: {e}\")\n",
        "else:\n",
        "    print(f\"Directory '{directory_to_clean}' not found.\")"
      ],
      "metadata": {
        "id": "5wEFkk-121KE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Feature engineering"
      ],
      "metadata": {
        "id": "PERUb1na5Azr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Prepare pipeline"
      ],
      "metadata": {
        "id": "Dw3RFpOgVUaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to calculate the angle\n",
        "def calculate_angle(lat, lon, lat_prev, lon_prev, lat_next, lon_next):\n",
        "    # Convert degrees to radians\n",
        "    lat = math.radians(lat)\n",
        "    lon = math.radians(lon)\n",
        "    lat_prev = math.radians(lat_prev)\n",
        "    lon_prev = math.radians(lon_prev)\n",
        "    lat_next = math.radians(lat_next)\n",
        "    lon_next = math.radians(lon_next)\n",
        "\n",
        "    # Compute vectors in 3D Cartesian coordinates\n",
        "    def to_cartesian(lat, lon):\n",
        "        x = math.cos(lat) * math.cos(lon)\n",
        "        y = math.cos(lat) * math.sin(lon)\n",
        "        z = math.sin(lat)\n",
        "        return (x, y, z)\n",
        "\n",
        "    p1 = to_cartesian(lat_prev, lon_prev)\n",
        "    p2 = to_cartesian(lat, lon)\n",
        "    p3 = to_cartesian(lat_next, lon_next)\n",
        "\n",
        "    # Calculate vectors\n",
        "    v1 = (p1[0] - p2[0], p1[1] - p2[1], p1[2] - p2[2])\n",
        "    v2 = (p3[0] - p2[0], p3[1] - p2[1], p3[2] - p2[2])\n",
        "\n",
        "    # Compute magnitudes of vectors\n",
        "    mag_v1 = math.sqrt(sum(v1[i]**2 for i in range(3)))\n",
        "    mag_v2 = math.sqrt(sum(v2[i]**2 for i in range(3)))\n",
        "\n",
        "    # Handle zero magnitude vectors\n",
        "    if mag_v1 == 0 or mag_v2 == 0:\n",
        "        return float('nan')  # Return NaN for undefined angle\n",
        "\n",
        "    # Compute dot product\n",
        "    dot_product = sum(v1[i] * v2[i] for i in range(3))\n",
        "\n",
        "    # Calculate the angle using the dot product formula\n",
        "    cos_theta = dot_product / (mag_v1 * mag_v2)\n",
        "    angle = math.acos(max(-1, min(1, cos_theta)))  # Clamp to avoid numerical issues\n",
        "\n",
        "    # Convert radians to degrees\n",
        "    angle_degrees = math.degrees(angle)\n",
        "    return angle_degrees"
      ],
      "metadata": {
        "id": "WM-8KQJx90sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read one test file\n",
        "df = pd.read_excel('/content/Rider1_preprocessed/f1.xlsx')\n",
        "\n",
        "# Assuming 'df' is your DataFrame as defined in the previous code.\n",
        "df['Latitude_prev'] = df['Latitude'].shift(1)\n",
        "df['Longitude_prev'] = df['Longitude'].shift(1)\n",
        "df['Elevation_prev'] = df['Elevation'].shift(1)\n",
        "df['Latitude_next'] = df['Latitude'].shift(-1)\n",
        "df['Longitude_next'] = df['Longitude'].shift(-1)\n",
        "df['Elevation_next'] = df['Elevation'].shift(-1)\n",
        "\n",
        "# Calculate speed based on distance and time differences\n",
        "df['Time_prev'] = df['Time'].shift(1)\n",
        "df['Time_next'] = df['Time'].shift(-1)\n",
        "df['Distance_prev'] = df['Distance'].shift(1)\n",
        "df['Distance_next'] = df['Distance'].shift(-1)\n",
        "\n",
        "# Calculate time difference\n",
        "df['Time_diff_prev'] = df['Time'] - df['Time_prev']\n",
        "df['Time_diff_next'] = df['Time_next'] - df['Time']\n",
        "\n",
        "# Calculate distance difference\n",
        "df['Distance_diff_prev'] = df['Distance'] - df['Distance_prev']\n",
        "df['Distance_diff_next'] = df['Distance_next'] - df['Distance']\n",
        "\n",
        "# Calculate speed (m/s)\n",
        "df['Speed'] = (df['Distance_diff_next'] + df['Distance_diff_prev']) / (df['Time_diff_next'] + df['Time_diff_prev'])\n",
        "\n",
        "# Calculate slope\n",
        "df['Slope_prev'] = (df['Elevation'] - df['Elevation_prev']) / (df['Distance'] - df['Distance_prev'])\n",
        "df['Slope_next'] = (df['Elevation_next'] - df['Elevation']) / (df['Distance_next'] - df['Distance'])\n",
        "\n",
        "# Handle potential divisions by zero\n",
        "df['Slope_prev'] = df['Slope_prev'].fillna(0).replace([float('inf'), -float('inf')], 0)\n",
        "df['Slope_next'] = df['Slope_next'].fillna(0).replace([float('inf'), -float('inf')], 0)\n",
        "\n",
        "# Calculate angle between next and previous points\n",
        "df['Angle'] = df.apply(\n",
        "    lambda row: calculate_angle(\n",
        "        row['Latitude'], row['Longitude'],\n",
        "        row['Latitude_prev'], row['Longitude_prev'],\n",
        "        row['Latitude_next'], row['Longitude_next']\n",
        "    ), axis=1\n",
        ")\n",
        "\n",
        "# Calculate the sum of the slopes driven so far\n",
        "df['Cumulative_Slope'] = df['Slope_prev'].cumsum()\n",
        "\n",
        "# Rearrange columns\n",
        "df = df[['Elevation', 'Slope_prev', 'Slope_next',  'Angle', 'Distance', 'Cumulative_Slope', 'Speed', 'Time']]\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "SC2706GM58Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Divide into train/test"
      ],
      "metadata": {
        "id": "C05Jun4QN_Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing the Excel files\n",
        "directory = '/content/Rider1_preprocessed'\n",
        "destination_directory = '/content/Rider1_test'\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dataframes = []\n",
        "\n",
        "# Counters\n",
        "all_files = 0\n",
        "corrupted_files = 0\n",
        "files_count = 0\n",
        "\n",
        "# Create destination directory if it does not exist\n",
        "if not os.path.exists(destination_directory):\n",
        "    os.makedirs(destination_directory)\n",
        "\n",
        "# Iterate over all files in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.xlsx'):  # Process only .xlsx files\n",
        "        filepath = os.path.join(directory, filename)\n",
        "\n",
        "        # Read the Excel file into a DataFrame\n",
        "        df = pd.read_excel(filepath)\n",
        "\n",
        "        # Apply preprocessing\n",
        "        df['Latitude_prev'] = df['Latitude'].shift(1)\n",
        "        df['Longitude_prev'] = df['Longitude'].shift(1)\n",
        "        df['Elevation_prev'] = df['Elevation'].shift(1)\n",
        "        df['Latitude_next'] = df['Latitude'].shift(-1)\n",
        "        df['Longitude_next'] = df['Longitude'].shift(-1)\n",
        "        df['Elevation_next'] = df['Elevation'].shift(-1)\n",
        "\n",
        "        # Calculate speed based on distance and time differences\n",
        "        df['Time_prev'] = df['Time'].shift(1)\n",
        "        df['Time_next'] = df['Time'].shift(-1)\n",
        "        df['Distance_prev'] = df['Distance'].shift(1)\n",
        "        df['Distance_next'] = df['Distance'].shift(-1)\n",
        "\n",
        "        # Calculate time difference\n",
        "        df['Time_diff_prev'] = df['Time'] - df['Time_prev']\n",
        "        df['Time_diff_next'] = df['Time_next'] - df['Time']\n",
        "\n",
        "        # Calculate distance difference\n",
        "        df['Distance_diff_prev'] = df['Distance'] - df['Distance_prev']\n",
        "        df['Distance_diff_next'] = df['Distance_next'] - df['Distance']\n",
        "\n",
        "        # Calculate speed (m/s)\n",
        "        df['Speed'] = (df['Distance_diff_next'] + df['Distance_diff_prev']) / (df['Time_diff_next'] + df['Time_diff_prev'])\n",
        "\n",
        "        # Calculate slope\n",
        "        df['Slope_prev'] = (df['Elevation'] - df['Elevation_prev']) / (df['Distance'] - df['Distance_prev'])\n",
        "        df['Slope_next'] = (df['Elevation_next'] - df['Elevation']) / (df['Distance_next'] - df['Distance'])\n",
        "\n",
        "        # Handle potential divisions by zero\n",
        "        df['Slope_prev'] = df['Slope_prev'].fillna(0).replace([float('inf'), -float('inf')], 0)\n",
        "        df['Slope_next'] = df['Slope_next'].fillna(0).replace([float('inf'), -float('inf')], 0)\n",
        "\n",
        "        # Calculate angle between next and previous points\n",
        "        df['Angle'] = df.apply(\n",
        "            lambda row: calculate_angle(\n",
        "                row['Latitude'], row['Longitude'],\n",
        "                row['Latitude_prev'], row['Longitude_prev'],\n",
        "                row['Latitude_next'], row['Longitude_next']\n",
        "            ), axis=1\n",
        "        )\n",
        "\n",
        "        # Calculate the sum of the slopes driven so far\n",
        "        df['Cumulative_Slope'] = df['Slope_prev'].cumsum()\n",
        "\n",
        "        # Rearrange columns\n",
        "        df = df[['Elevation', 'Slope_prev', 'Slope_next',  'Angle', 'Distance', 'Cumulative_Slope', 'Speed', 'Time']]\n",
        "\n",
        "        # Drop NaN values\n",
        "        df = df.dropna()\n",
        "\n",
        "        # if negative elevation\n",
        "        if (df['Elevation'] < 0).any() or (df['Slope_prev'].abs() > 1.0).any() or (df['Slope_next'].abs() > 1.0).any() or (df['Speed'] > 25).any():\n",
        "            all_files += 1\n",
        "            corrupted_files += 1\n",
        "            # Append the processed DataFrame to the list\n",
        "            dataframes.append(df)\n",
        "            continue\n",
        "\n",
        "        # Count all files\n",
        "        all_files += 1\n",
        "\n",
        "        # Move first 10 uncorrupted files to test folder\n",
        "        if files_count < 10:\n",
        "            destination_dir = os.path.join(destination_directory, filename)\n",
        "            try:\n",
        "                destination_dir_csv = destination_dir[:-5] + \".csv\"\n",
        "                df.to_csv(destination_dir_csv, index=False)\n",
        "                print(f\"Converted {filename} to {destination_dir_csv}\")\n",
        "                files_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Error moving {filename}: {e}\")\n",
        "        else:\n",
        "            # Append the processed DataFrame to the list\n",
        "            dataframes.append(df)\n",
        "\n",
        "# Combine all DataFrames into a single DataFrame\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "# Display the first few rows of the combined DataFrame\n",
        "print(combined_df.head())\n",
        "\n",
        "# Print results\n",
        "print(f\"Corrupted files: {corrupted_files}\")\n",
        "print(f\"All files: {all_files}\")"
      ],
      "metadata": {
        "id": "LyTH_2hdOA4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore dataset"
      ],
      "metadata": {
        "id": "HJqiOB7k84tH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histograms for all columns in the DataFrame\n",
        "for column in combined_df.columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(combined_df[column], bins=50, edgecolor='k', alpha=0.7)\n",
        "    plt.title(f\"Histogram of {column}\")\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Ll_Hxi62YPx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Data cleaning"
      ],
      "metadata": {
        "id": "HlvGgrkn87iZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean combined_df: Remove rows with negative elevation, remove slope higher than abs(1.0), remove speed > 75, write a summary how many rows were deleted and how many are left\n",
        "# Original row count\n",
        "original_row_count = len(combined_df)\n",
        "\n",
        "# Remove rows with negative elevation\n",
        "combined_df = combined_df[combined_df['Elevation'] >= 0]\n",
        "\n",
        "# Remove rows with slope higher than abs(1.0)\n",
        "combined_df = combined_df[combined_df['Slope_prev'].abs() <= 1.0]\n",
        "combined_df = combined_df[combined_df['Slope_next'].abs() <= 1.0]\n",
        "\n",
        "# Remove rows with speed > 25\n",
        "combined_df = combined_df[combined_df['Speed'] <= 25]\n",
        "\n",
        "# Calculate the number of deleted rows\n",
        "deleted_rows = original_row_count - len(combined_df)\n",
        "\n",
        "# Print summary\n",
        "print(f\"Original number of rows: {original_row_count}\")\n",
        "print(f\"Number of deleted rows: {deleted_rows}\")\n",
        "print(f\"Remaining number of rows: {len(combined_df)}\")"
      ],
      "metadata": {
        "id": "Tm_7HQepWqqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot histograms for all columns in the DataFrame\n",
        "for column in combined_df.columns:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(combined_df[column], bins=50, edgecolor='k', alpha=0.7)\n",
        "    plt.title(f\"Histogram of {column}\")\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "W1MoaKDn4n2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Export train and test\n",
        "Export csv file containig all the training rows, and export zipped test files."
      ],
      "metadata": {
        "id": "7giPTELB9FBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the combined DataFrame to a file\n",
        "combined_df.to_csv('/content/combined_data_r1.csv', index=False)"
      ],
      "metadata": {
        "id": "f3dhHgfQYRS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# zip /content/Rider1_test directory\n",
        "!zip -r /content/Rider1_test.zip /content/Rider1_test"
      ],
      "metadata": {
        "id": "qe5GiruN9uE5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
